# ğŸ¬ Recommendation-system-for-movies-using-clustering-and-NLP-approaches 

The project focuses on creating a content-based recommendation system for movies. 
The project includes cleaning, analyzing and preparing data about films using NLP approaches like tokenization, stemming, vectorization in order to create clusters. 
For creating recommendations, a console application was made where a user can enter a film that he likes and then get recommendations based on that film.



## ğŸ“ Project Structure

```
Recommendation-system-for-movies-using-clustering-and-NLP-approaches/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw_data/
â”‚ â”‚ â”œâ”€â”€ credits.csv
â”‚ â”‚ â”œâ”€â”€ movies_metadata.csv
â”‚ â”œâ”€â”€ cluster_labels.csv
â”‚ â”œâ”€â”€ preprocessed_data.csv
â”‚
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ kmeans_model.joblib
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ data.ipynb
â”‚ â”œâ”€â”€ modeling.ipynb
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
```

- data/ folder with raw and processed data.
- models/ folder with trained model.
- notebooks/ folder with jupyter notebooks.
- README.md provides project overview and instructions.
- app.py consol application for getting recommendations.
- requirements.txt specifies Python dependencies.



## ğŸ“Š Dataset 

The dataset used is a publicly available dataset from Kaggle called 'The Movies Dataset'. The dataset contains metadata for 45,000 movies. 
It consists of movies released on or before July 2017. Data points include title, posters, backdrops, budget, revenue, release dates, languages, description, production countries, 
and companies from movies_metadata.csv, as well as information about cast and crew from credits.csv. <br>

Source: https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset 



## ğŸ› ï¸ Data processing 

Before creating clusters, we need to explore and preprocess our data. <br>

It includes: <br>
1. Basic exploration and preprocessing (check and clean data) <br>
2. Text data preprocessing (tokenization, removing stop words, stemming) <br>
3. Analysis of the data (histograms, bar plots, scatter plots) <br>
4. Vectorization of the data (TfidfVectorizer and CountVectorizer) <br>
5. Reduction of dimensionality (PCA) <br>
6. Saving the preprocessed data <br>

Code and explanation are available in data.ipynb.



## ğŸ¤– Modeling 

In this step, we are going to apply a clustering algorithm on our preprocessed data. In this project, we used one of the most common algorithms â€” KMeans, 
because it needs only one parameter and works well with large data. <br>

It includes: <br>
1. Getting the optimal number of clusters (elbow method and silhouette score) <br>
2. Training the model with the optimal k <br>
3. Exploring and visualizing the clusters (bar plot, UMAP) <br>
4. Saving the model and necessary data for the recommendation system <br>

Code and explanation are available in modeling.ipynb.



## â­ Creating recommendations

The recommendation system works as follows: the user enters a movie they like (this can be done using the console application app.py). 
Then the cluster of this movie is found, along with other movies that belong to the same cluster. 
After that, based on Euclidean distance, the movies closest to the userâ€™s movie in this cluster are selected.



## ğŸ† Results

hgehehrerh



## ğŸ› ï¸ Tools Used

- Python (Pandas, Numpy, nltk, Matplotlib, Scikit-learn, UMAP, Joblib)
- Jupyter Notebook



## âš¡ Installation

1. Clone the repository: <br>

   `git clone https://github.com/TheDim0nu4/Recommendation-system-for-movies-using-clustering-and-NLP-approaches.git` <br>
   `cd Recommendation-system-for-movies-using-clustering-and-NLP-approaches` <br>
   
2. Create a Python virtual environment (optional but recommended): <br>

   `python -m venv venv` <br>

3. Install the required dependencies: <br>

   `pip install -r requirements.txt` <br>



## âœï¸ Author

This project was implemented in the autumn of 2025. The project was carried out by Dmytro Skrypchenko.




